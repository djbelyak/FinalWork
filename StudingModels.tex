\section{Алгоритмы обучения нейронных сетей}

Самым важным свойством нейронных сетей является их способность обучаться на основе данных окружающей среды и в  результате обучения повышать свою производительность.
Повышение производительности происходит со временем в соответствии с определёнными правилами.
Обучение нейронной сети происходит посредством интерактивного
процесса корректировки синаптических весов и порогов.
В идеальном случае нейронная сеть получает знания об окружающей среде на каждой итерации процесса обучения.

С понятием обучения ассоциируется довольно много видов деятельности, поэтому сложно дать этому процессу однозначное определение.
С позиций нейронных сетей мы можем использовать следующее определение обучения
\begin{Def}
Обучение ---  это процесс, в котором свободные параметры нейронной сети настраиваются посредством моделирования среды, в которую эта сеть встроена.
Тип обучения определяется способом подстройки этих параметров. 
\end{Def}

Это определение предполагает следующую последовательность событий при обучении нейронной сети:

\begin{enumerate}
	\item В нейронную сеть поступают стимулы из внешней среды.

	\item В результате этого изменяются свободные параметры нейронной сети.

	\item После изменения внутренней структуры нейронная сеть отвечает на возбуждения уже иным образом.
\end{enumerate}

Вышеуказанный список четких правил решения проблемы обучения называется алгоритмом обучения. 
Несложно догадаться, что не существует универсального алгоритма обучения, подходящего для всех архитектур нейронных сетей.
Существует лишь набор средств, предоставленный множеством алгоритмов обучения, каждый из которых имеет свои достоинства.\cite{NejronnyeSeti}

\subsection{Обучение на основе коррекции ошибок}

Для того, чтобы проиллюстрировать первое правило обучения, рассмотрим простейший случай нейрона $k$ --- единственного вычислительного узла выходного слоя нейронной сети прямого распространения.
Нейрон $k$ работает под управлением вектора сигнала $\vec x (n)$, производимого одним или несколькими скрытыми слоями нейронов, которые в свою очередь получают информацию из входного вектора, передаваемого начальным узлам нейронной сети.
Под $n$ подразумевается дискретное время или, более конкретно, --- номер шага итеративного процесса настройки синаптических весов нейрона $k$.
Выходной сигнал нейрона $k$ обозначается $y_k(n)$.
Этот сигнал будет сравниваться с желаемым выходом, обозначенным $d_k(n)$.
В результате получим сигнал ошибки $e_k(n)$.
По определению
\begin{equation}
e_k(n) = y_k(n) - d_k(n)
\end{equation}

Сигнал ошибки инициализирует механизм управления, цель которого заключается применении последовательности корректировок к синаптическим весам нейрона $k$.
Эти изменения нацелены на пошаговое приближение выходного сигнала $y_k(n)$ к желаемому $d_k(n)$.
Эта цель достигается за счет минимизации функции стоимости или индекса производительности $E(n)$, определяемой в терминах сигнала ошибки следующим образом:
\begin{equation}
E(n) = \frac12 e_k^2(n)
\end{equation}
где $E(n)$ --- текущее значение энергии ошибки.
Пошаговая корректировка синаптических весов нейрона $k$  продолжается пока до тех пор, пока система не достигнет устойчивого состояния.
В этой точке процесс обучения останавливается.

Процесс, описанный выше, называется обучением на основе коррекции ошибок.
Минимизация функции стоимости $E(n)$ выполняется по так называемому дельта-правилу, или правилу Видроу-Хоффа, названному в честь его создателей.
Обозначим $\omega_{kj}(n)$  текущее значение синаптического веса $\omega_{kj}$ нейрона $k$, соответствующему элементу $x_j(n)$ вектора $\vec x(n)$, на шаге дискретизации $n$.
В соответствии с дельта-правилом изменение $\Delta\omega_{kj}(n)$, применяемое  к синаптическому весу $\omega_{kj}$ на этом шаге дискретизации, задается выражением
\begin{equation}
\Delta\omega_{kj}(n) = \eta e_k(n)x_j(n)
\end{equation}
где $\eta$ --- некоторая положительная константа, определяющая скорость обучения и используемая при переходе  от одного шага процесса к другому. 
Эту константу естественно именовать параметром скорости обучения.
Вербально дельта-правило можно определить следующим образом:

Корректировка, применяемая к синаптическому весу нейрона, пропорциональна произведению сигнала ошибки на входной сигнал, его вызвавший.

Необходимо помнить, что  определенное таким образом дельта-правило предполагает возможность прямого измерения сигнала ошибки.
Для обеспечения такого измерения требуется поступление желаемого отклика от некоторого внешнего источника, непосредственно доступного для нейрона $k$.
Другими словами нейрон $k$ должен быть видимым для внешнего мира.
Вычислив величину изменения синаптического веса $\Delta\omega_{kj}(n)$, можно определить его новое значение для следующего шага дискретизации:
\begin{equation}
\Delta\omega_{kj}(n+1) = \omega_{kj}(n) +\Delta\omega_{kj}(n)
\end{equation}

\subsection{Конкурентное обучение}

Как следует из самого названия, в конкурентном обучении выходные нейроны нейронной сети конкурируют между собой за право быть активизированными.
Благодаря этому свойству конкурентное обучение очень удобно использовать для изучения статистических свойств, используемых в задачах классификации входных образов. 
Правило конкурентного обучения основано на использовании трех основных элементов.
\begin{itemize}
\item Множество одинаковых нейронов со случайно распределенными синаптическими весами, приводящими к различной реакции нейронов на один и тот же входной сигнал.
\item Предельное значение <<силы>> каждого нейрона
\item Механизм, позволяющий нейронам конкурировать за право отклика на данное подмножество входных сигналов  и определяющий единственный активный выходной нейрон.
Нейрон, победивший в этом соревновании, называют нейроном-победителем, а принцип конкурентного обучения формулируют в виде лозунга <<победитель забирает все>> 
\end{itemize}
